{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be creating a simple character-level Recurrent Neural Network (RNN) to classify city names into their respective countries.\n",
    "\n",
    "This character-level RNN will read a city name as a sequence of characters. We will use the data from [simplemap.com](https://simplemaps.com/data/world-cities). The data is preprocessed by extracting the some number of top countries and randomly sampling their respective cities. Then, the data is splitted into a train dataset and test dataset.  \n",
    "\n",
    "# Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "train_data = pd.read_csv(\"../data/train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_data = train_data[\"city\"].values\n",
    "train_target_data = train_data[\"country\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load a list of unique characters in the city names. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load unique charss from unique_chars.json\n",
    "with open(\"../data/unique_chars.json\", \"r\") as f:\n",
    "    unique_chars = json.load(f)\n",
    "print(unique_chars[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the city names into Pytorch Tensors \n",
    "\n",
    "We will prepare some utility functions to convert the city names into PyTorch Tensors by using one-hot encoding. Our one-hot vector has a length of the number of unique characters, with a 1 at the index of the current character and 0 everywhere else.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "n_letters = len(unique_chars)\n",
    "\n",
    "\n",
    "# Function to find the index of a letter without predefining all_letters\n",
    "def letterToIndex(letter):\n",
    "    return unique_chars.index(letter)\n",
    "\n",
    "\n",
    "# Function to convert a string into a Tensor of shape <line_length x 1 x n_letters>\n",
    "# Each character in the string is represented as a one-hot vector\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# Demonstration of converting a letter and a string into Tensors\n",
    "print(lineToTensor(\"B\"))\n",
    "\n",
    "# Demonstration of converting a city name into a sequence of Tensors\n",
    "print(lineToTensor(\"Binghamton\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will convert the country names into PyTorch Tensors. We will assign a unique integer to each country. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_countries = np.unique(train_target_data)\n",
    "country_to_index = {country: i for i, country in enumerate(unique_countries)}\n",
    "train_target = train_data[\"country\"].apply(lambda x: country_to_index[x]).values\n",
    "\n",
    "# Or alternatively\n",
    "# train_target = np.unonique(train_data[\"country\"], return_inverse=True)[1]\n",
    "\n",
    "train_target_data_tensor = torch.tensor(train_target)\n",
    "train_target_data_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Dataset and Data loader\n",
    "\n",
    "We will create a custom dataset that takes the city names and the country names as input and returns the city names and the country names as an integer tensor.\n",
    "\n",
    "Then, we will create a data loader with a batch size of 512. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a custom dataset class using torch.utils.data.Dataset\n",
    "class CityCountryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, cities, countries):\n",
    "        self.cities = ...\n",
    "        self.countries = ...\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of samples in the dataset\"\"\"\n",
    "        # TODO: Implement\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return the sample with the given index idx\"\"\"\n",
    "        # TODO: Implement\n",
    "        pass\n",
    "\n",
    "\n",
    "# TODO: Create the CityCountryDataset object\n",
    "train_dataset = ...\n",
    "\n",
    "# TODO:  Create a DataLoader from the dataset with batch_size=32~512\n",
    "train_dataloader = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the RNNs\n",
    "\n",
    "Let's create a simple RNN with two linear layers.\n",
    "* The input and hidden states will be concatenated first. \n",
    "* One layer computes the next hidden state, and another layer computes the output. \n",
    "* Tanh function is applied to the hidden state.  \n",
    "* No non-linear activation function is applied to the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the RNN class\n",
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \"\"\"Initialize the RNN with the given input, hidden, and output size\"\"\"\n",
    "        # TODO: Implement\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"Forward pass of the RNN\"\"\"\n",
    "        # TODO: Implement\n",
    "        pass\n",
    "\n",
    "    def initHidden(self):\n",
    "        \"\"\"Return a tensor of shape <1 x hidden_size> filled with zeros\"\"\"\n",
    "        # TODO: Implement\n",
    "        pass\n",
    "\n",
    "\n",
    "# TODO: Define the RNN model with hidden size 128\n",
    "rnn = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a city name, we need to run the RNN on each character of the city name. Then, we will take the output of the RNN for the last character as the final output.  \n",
    "\n",
    "Let's prepare a utility function to predict the country from the city name. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run the RNN on the city name\n",
    "def run_rnn(city_name, rnn):\n",
    "    \"\"\"Run the RNN on the given city name\n",
    "\n",
    "    input:\n",
    "    city_name: str\n",
    "    rnn: RNN\n",
    "\n",
    "    output:\n",
    "    output: Tensor of shape <1 x n_countries>\n",
    "    \"\"\"\n",
    "\n",
    "    # HINT: Initialize the hidden state\n",
    "\n",
    "    # HINT Convert the city name into a Tensor\n",
    "\n",
    "    # HINT Run the RNN on the input tensor\n",
    "\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train!\n",
    "\n",
    "## Preparation for the training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `CrossEntropyLoss` as the loss function. This loss function is useful to train a model for multiclass classification. ([link](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ...  # TODO: Define the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ...  # TODO: Define the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 2  # number of epochs\n",
    "loss_values = []  # to store the loss values at each step\n",
    "\n",
    "# Set the model to training mode\n",
    "...\n",
    "\n",
    "# TODO: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_values)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_country(city_name, rnn):\n",
    "    output = run_rnn(city_name, rnn)\n",
    "    country_index = torch.argmax(output)\n",
    "    return unique_countries[country_index]\n",
    "\n",
    "\n",
    "city_name = \"New York\"\n",
    "predict_country(city_name, rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction won't be perfect because the model is trained on a small dataset. However, the model should be better than random. Let's check.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test data\n",
    "test_data = pd.read_csv(\"../../data/test.csv\")\n",
    "test_data.head()\n",
    "\n",
    "# Make predictions\n",
    "predictions = [\n",
    "    predict_country(city_name, rnn) for city_name in test_data[\"city\"].values\n",
    "]\n",
    "\n",
    "# Compute the accuracy of the model\n",
    "accuracy = (predictions == test_data[\"country\"]).mean()\n",
    "\n",
    "# Compute the accuracy of the random model\n",
    "random_accuracy = 1 / len(unique_countries)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Random accuracy: {random_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit the results \n",
    "\n",
    "Please **git commit & push** the following two files created in the following cell. \n",
    "\n",
    "1. \"~/assignments/rnn_test_predictions.csv\" \n",
    "\n",
    "2. \"~/assignments/rnn_loss_values.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions).to_csv(\"./predictions.csv\", index=False)\n",
    "pd.DataFrame(loss_values).to_csv(\"./loss_values.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applsoftcomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
